{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 검색 챗봇 만들기 LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q grobid-client langchain openai faiss-cpu PyPDF2 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess a PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q&A로 풀어본 \\nAI 학습용 데이터\\n상세 매뉴얼2019Q&A로 풀어본 \\nAI 학습용 데이터\\n상세 매뉴얼2019\\nContents\\n한국어-영어 번역 말뭉치 AI 데이터  2 1\\n이상행동 CCTV 영상 AI 데이터  6 2\\n한국어 글자체 이미지 AI 데이터  10 3\\n인도 보행 영상 AI 데이터  14 4\\n멀티모달 영상 AI 데이터  22 5\\n사람 동작 영상 AI데이터  26 6\\n한국인 안면 이미지 AI 데이터  30 7\\n위해물품 엑스레이 이미지 AI 데이터  34 8\\n질병진단 이미지 AI 데이터  38 9\\n이상행동 CCTV 영상 AI 데이터  45 102\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼한국어-영어 번역 말뭉치 AI 데이터\\n  세계는 이미 신경망 번역( NMT, Neural  Machine  Translation ) 엔진을 사용하는 것이 일반화되어, 용도에 맞는 제품과 \\n서비스를 만들어 기존의 번역을 혁신하는 단계가 되었으나, 국내 자동번역/인공지능 번역 연구개발은 대규모 고품질의 \\n말뭉치가 부족하여 개별 기업이 자체적 기술 개발에 한계\\n  최근 기업에 신경망 번역 엔진을 공식적으로 도입하여 사용하는 사례가 증가하고 향후 업무 활용 및 연구개발이 더욱 \\n활발해질 것으로 기대함에 따라 공공 번역 말뭉치를 구축하여 공개함 \\n  신경망 번역 성능 향상을 위한 고품질 한국어-영어 번역 말뭉치 셋 160만 문장 구축; 뉴스 80만, 지자체 웹사이트 10만, \\n조례 10만, 한국문화 10만, 구어체 40만, 대화체 10만1\\n구축 공정필요성  \\n구축 내용Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\\n구축 기관 (주)솔트룩스파트너스, (주)에버트란, (주)플리토\\n수집 정제 번역 검수 배포3\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼수집된 뉴스데이터 종류는 무엇인가요?Q\\nA대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \\n한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = PdfReader(\"./assets/qna-samples/ai_manual.pdf\")\n",
    "\n",
    "raw_text = \"\"\n",
    "\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "raw_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heewungsong/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heewungsong/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' This document provides a detailed manual for AI training data, including various types of images and videos collected and refined by three companies. The data is valuable for developing AI translation engines and can be used for various purposes such as legal translation and social media. The manual also explains the process of collecting, refining, and verifying the data using annotation and ontology tools. It includes information on the dataset, image and annotation information, and licensing. The data is used for various applications such as autonomous driving and emotion analysis. The manual also discusses the development of an AI learning dataset for human motion recognition and emotion analysis. It includes a large database of facial images for facial recognition technology. The data set also includes X-ray images for airport and port security. The data is collected and processed with strict adherence to privacy laws and regulations. The report also discusses the need for AI data for abnormal behavior CCTV footage and the process of collecting, refining, and distributing the data. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_document_chain.run(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering 질문 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heewungsong/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\") # gpt-3.5-turbo, gpt-4\n",
    "\n",
    "qa_chain = load_qa_chain(model, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송합니다. 해당 문서의 목차가 포함되어 있지 않습니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=raw_text,\n",
    "    question=\"문서의 목차를 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사물 이미지 데이터의 구축 공정은 일반적으로 다음과 같은 단계로 이루어집니다:\\n\\n1. 데이터 수집: 사물 이미지 데이터를 수집하기 위해 다양한 방법을 사용합니다. 이는 인터넷에서 이미지를 크롤링하거나, 사진을 찍어서 데이터를 수집하는 것 등이 포함될 수 있습니다.\\n\\n2. 데이터 정제: 수집된 데이터는 정제 작업을 거쳐야 합니다. 이 단계에서는 중복되거나 품질이 낮은 이미지를 제거하고, 필요한 정보를 추출하여 데이터를 정리합니다.\\n\\n3. 어노테이션 작업: 이미지 내의 사물을 식별하고 분류하기 위해 어노테이션 작업을 수행합니다. 어노테이션은 주로 바운딩 박스, 세그멘테이션 마스크, 키포인트 등의 형태로 이루어집니다. 이 과정에서는 사물의 위치, 크기, 형태 등을 정확하게 표시하여 이미지에 대한 정보를 제공합니다.\\n\\n4. 데이터 포맷 변환: 어노테이션 작업이 완료된 데이터를 필요한 포맷으로 변환합니다. 이를 통해 다양한 딥러닝 프레임워크나 학습 알고리즘에서 사용할 수 있는 형태로 데이터를 구성합니다. 일반적으로 XML, JSON, CSV 등의 형식으로 데이터를 저장하고 관리합니다.\\n\\n5. 데이터 검수: 어노테이션 작업이 완료된 데이터를 검수하여 품질을 확인합니다. 이 과정에서 오검출, 미검출, 과검출 등의 문제를 확인하고 수정하는 작업이 이루어집니다. 검수를 통해 데이터의 정확성과 일관성을 유지하고 데이터셋의 품질을 관리합니다.\\n\\n6. 데이터 확장: 구축된 데이터셋을 확장하기 위해 필요한 추가 작업을 수행합니다. 이는 데이터 수집, 어노테이션 작업, 데이터 정제 등의 단계를 반복하여 데이터셋의 크기와 다양성을 향상시킵니다.\\n\\n7. 데이터 배포: 최종적으로 구축된 데이터는 공개 사이트나 라벨링 시스템을 통해 배포됩니다. 이를 통해 데이터를 수정하거나 추가 데이터를 업로드하여 다른 연구/개발자들이 활용할 수 있도록 합니다.\\n\\n이와 같은 과정을 거쳐 구축된 사물 이미지 데이터는 다양한 분야에서 컴퓨터 비전 및 인공지능 알고리즘의 학습과 평가에 사용될 수 있습니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=raw_text,\n",
    "    question=\"사물 이미지 데이터의 구축공정에 대해 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitters\n",
    "\n",
    "pdf 파일이 크기 때문에 적당한 크기로 split함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have 40673 texts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = PdfReader(\"./assets/qna-samples/ai_manual.pdf\")\n",
    "\n",
    "raw_text = \"\"\n",
    "\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "f\"You have {len(raw_text)} texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "documents = text_splitter.create_documents([raw_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have 46 documents'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"You have {len(documents)} documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A로 풀어본 \n",
      "AI 학습용 데이터\n",
      "상세 매뉴얼2019Q&A로 풀어본 \n",
      "AI 학습용 데이터\n",
      "상세 매뉴얼2019\n",
      "Contents\n",
      "한국어-영어 번역 말뭉치 AI 데이터  2 1\n",
      "이상행동 CCTV 영상 AI 데이터  6 2\n",
      "한국어 글자체 이미지 AI 데이터  10 3\n",
      "인도 보행 영상 AI 데이터  14 4\n",
      "멀티모달 영상 AI 데이터  22 5\n",
      "사람 동작 영상 AI데이터  26 6\n",
      "한국인 안면 이미지 AI 데이터  30 7\n",
      "위해물품 엑스레이 이미지 AI 데이터  34 8\n",
      "질병진단 이미지 AI 데이터  38 9\n",
      "이상행동 CCTV 영상 AI 데이터  45 102\n",
      "Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼한국어-영어 번역 말뭉치 AI 데이터\n",
      "  세계는 이미 신경망 번역( NMT, Neural  Machine  Translation ) 엔진을 사용하는 것이 일반화되어, 용도에 맞는 제품과 \n",
      "서비스를 만들어 기존의 번역을 혁신하는 단계가 되었으나, 국내 자동번역/인공지능 번역 연구개발은 대규모 고품질의 \n",
      "말뭉치가 부족하여 개별 기업이 자체적 기술 개발에 한계\n",
      "  최근 기업에 신경망 번역 엔진을 공식적으로 도입하여 사용하는 사례가 증가하고 향후 업무 활용 및 연구개발이 더욱 \n",
      "활발해질 것으로 기대함에 따라 공공 번역 말뭉치를 구축하여 공개함 \n",
      "  신경망 번역 성능 향상을 위한 고품질 한국어-영어 번역 말뭉치 셋 160만 문장 구축; 뉴스 80만, 지자체 웹사이트 10만, \n",
      "조례 10만, 한국문화 10만, 구어체 40만, 대화체 10만1\n",
      "구축 공정필요성  \n",
      "구축 내용Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\n",
      "구축 기관 (주)솔트룩스파트너스, (주)에버트란, (주)플리토\n",
      "수집 정제 번역 검수 배포3\n",
      "Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼수집된 뉴스데이터 종류는 무엇인가요?Q\n",
      "A대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \n",
      "\n",
      "A대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \n",
      "한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 \n",
      "수집하였습니다.\n",
      "수집된 뉴스데이터 세부종류는 무엇인가요?Q\n",
      "A세부분류 항목은 문화, 경제, 정치, 스포츠, IT, 국제, 지역, 사회의 8개 항목입니다.\n",
      "원문 정제의 기준은 무엇인가요?Q\n",
      "A160만 문장은 평균 20어절 이상입니다. 그리고 뉴스의 경우 비슷한 기사가 많아서 85% 이상 중복되는 문장은 \n",
      "수집하지 않았습니다. 정제\n",
      "데이터 학습을 위한 번역 문장의 특성이 있을까요?Q\n",
      "A문장과 문장이 쌍을 이루어 딥러닝 학습을 효율적으로 할 수 있도록 사업 초기에 구축 가이드라인을 설정하고 \n",
      "작업방식을 통일해서 데이터를 구축했습니다. 문장부호 및 고유명사, 단위나 수치 표시 지침을 정확하게 세우고 \n",
      "준수하도록 했습니다. 번역수집된 뉴스데이터 종류는 무엇인가요?Q\n",
      "A과업 결과물에 포함된 디지털 뉴스의 이용 허락 기간은 『 2019 한국어-영어 번역 말뭉치 AI데이터 구축』 사업의 \n",
      "결과물로 공개되는 기간까지로 정했습니다. 본 사업이 공개 데이터로 유지되는 기간은 저작권의 이슈가 발생하지 \n",
      "않습니다 수집4\n",
      "Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼데이터의 구조나 메타정보를 알려주세요.Q\n",
      "A구축 데이터는 엑셀 파일(*. xlsx)로 제공하고 번역 DB를 다운받아 수월하게 활용 가능합니다. 데이터의 모든 \n",
      "문장에는 문장번호를 부착하여 관리가 용이합니다. 배포Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\n",
      "구분 문장번호 출처 특성\n",
      "뉴스 ◯ 기사 URL 기사 작성일\n",
      "지자체 웹사이트 ◯\n",
      "조례 ◯ URL, 출판물\n",
      "구어체 ◯\n",
      "대화체 ◯ 대화세트/화자구분검수 시 번역 품질기준은 무엇인가요?Q\n",
      "A외부기관인 광운대학교 AI번역산업연구센터에서 본 결과물에 대한 품질검사를 진행했습니다. 목표량 검수 후\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content, \"\\n\")\n",
    "print(documents[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents, embedding, persist_directory=\"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=\"db\", \n",
    "    embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x16b873c10>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"수집된 뉴스데이터의 종류는?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \\n한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 \\n수집하였습니다.\\n수집된 뉴스데이터 세부종류는 무엇인가요?Q\\nA세부분류 항목은 문화, 경제, 정치, 스포츠, IT, 국제, 지역, 사회의 8개 항목입니다.\\n원문 정제의 기준은 무엇인가요?Q\\nA160만 문장은 평균 20어절 이상입니다. 그리고 뉴스의 경우 비슷한 기사가 많아서 85% 이상 중복되는 문장은 \\n수집하지 않았습니다. 정제\\n데이터 학습을 위한 번역 문장의 특성이 있을까요?Q\\nA문장과 문장이 쌍을 이루어 딥러닝 학습을 효율적으로 할 수 있도록 사업 초기에 구축 가이드라인을 설정하고 \\n작업방식을 통일해서 데이터를 구축했습니다. 문장부호 및 고유명사, 단위나 수치 표시 지침을 정확하게 세우고 \\n준수하도록 했습니다. 번역수집된 뉴스데이터 종류는 무엇인가요?Q\\nA과업 결과물에 포함된 디지털 뉴스의 이용 허락 기간은 『 2019 한국어-영어 번역 말뭉치 AI데이터 구축』 사업의 \\n결과물로 공개되는 기간까지로 정했습니다. 본 사업이 공개 데이터로 유지되는 기간은 저작권의 이슈가 발생하지 \\n않습니다 수집4\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼데이터의 구조나 메타정보를 알려주세요.Q\\nA구축 데이터는 엑셀 파일(*. xlsx)로 제공하고 번역 DB를 다운받아 수월하게 활용 가능합니다. 데이터의 모든 \\n문장에는 문장번호를 부착하여 관리가 용이합니다. 배포Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\\n구분 문장번호 출처 특성\\n뉴스 ◯ 기사 URL 기사 작성일\\n지자체 웹사이트 ◯\\n조례 ◯ URL, 출판물\\n구어체 ◯\\n대화체 ◯ 대화세트/화자구분검수 시 번역 품질기준은 무엇인가요?Q\\nA외부기관인 광운대학교 AI번역산업연구센터에서 본 결과물에 대한 품질검사를 진행했습니다. 목표량 검수 후'),\n",
       " Document(page_content='A대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \\n한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 \\n수집하였습니다.\\n수집된 뉴스데이터 세부종류는 무엇인가요?Q\\nA세부분류 항목은 문화, 경제, 정치, 스포츠, IT, 국제, 지역, 사회의 8개 항목입니다.\\n원문 정제의 기준은 무엇인가요?Q\\nA160만 문장은 평균 20어절 이상입니다. 그리고 뉴스의 경우 비슷한 기사가 많아서 85% 이상 중복되는 문장은 \\n수집하지 않았습니다. 정제\\n데이터 학습을 위한 번역 문장의 특성이 있을까요?Q\\nA문장과 문장이 쌍을 이루어 딥러닝 학습을 효율적으로 할 수 있도록 사업 초기에 구축 가이드라인을 설정하고 \\n작업방식을 통일해서 데이터를 구축했습니다. 문장부호 및 고유명사, 단위나 수치 표시 지침을 정확하게 세우고 \\n준수하도록 했습니다. 번역수집된 뉴스데이터 종류는 무엇인가요?Q\\nA과업 결과물에 포함된 디지털 뉴스의 이용 허락 기간은 『 2019 한국어-영어 번역 말뭉치 AI데이터 구축』 사업의 \\n결과물로 공개되는 기간까지로 정했습니다. 본 사업이 공개 데이터로 유지되는 기간은 저작권의 이슈가 발생하지 \\n않습니다 수집4\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼데이터의 구조나 메타정보를 알려주세요.Q\\nA구축 데이터는 엑셀 파일(*. xlsx)로 제공하고 번역 DB를 다운받아 수월하게 활용 가능합니다. 데이터의 모든 \\n문장에는 문장번호를 부착하여 관리가 용이합니다. 배포Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\\n구분 문장번호 출처 특성\\n뉴스 ◯ 기사 URL 기사 작성일\\n지자체 웹사이트 ◯\\n조례 ◯ URL, 출판물\\n구어체 ◯\\n대화체 ◯ 대화세트/화자구분검수 시 번역 품질기준은 무엇인가요?Q\\nA외부기관인 광운대학교 AI번역산업연구센터에서 본 결과물에 대한 품질검사를 진행했습니다. 목표량 검수 후'),\n",
       " Document(page_content='Q&A로 풀어본 \\nAI 학습용 데이터\\n상세 매뉴얼2019Q&A로 풀어본 \\nAI 학습용 데이터\\n상세 매뉴얼2019\\nContents\\n한국어-영어 번역 말뭉치 AI 데이터  2 1\\n이상행동 CCTV 영상 AI 데이터  6 2\\n한국어 글자체 이미지 AI 데이터  10 3\\n인도 보행 영상 AI 데이터  14 4\\n멀티모달 영상 AI 데이터  22 5\\n사람 동작 영상 AI데이터  26 6\\n한국인 안면 이미지 AI 데이터  30 7\\n위해물품 엑스레이 이미지 AI 데이터  34 8\\n질병진단 이미지 AI 데이터  38 9\\n이상행동 CCTV 영상 AI 데이터  45 102\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼한국어-영어 번역 말뭉치 AI 데이터\\n  세계는 이미 신경망 번역( NMT, Neural  Machine  Translation ) 엔진을 사용하는 것이 일반화되어, 용도에 맞는 제품과 \\n서비스를 만들어 기존의 번역을 혁신하는 단계가 되었으나, 국내 자동번역/인공지능 번역 연구개발은 대규모 고품질의 \\n말뭉치가 부족하여 개별 기업이 자체적 기술 개발에 한계\\n  최근 기업에 신경망 번역 엔진을 공식적으로 도입하여 사용하는 사례가 증가하고 향후 업무 활용 및 연구개발이 더욱 \\n활발해질 것으로 기대함에 따라 공공 번역 말뭉치를 구축하여 공개함 \\n  신경망 번역 성능 향상을 위한 고품질 한국어-영어 번역 말뭉치 셋 160만 문장 구축; 뉴스 80만, 지자체 웹사이트 10만, \\n조례 10만, 한국문화 10만, 구어체 40만, 대화체 10만1\\n구축 공정필요성  \\n구축 내용Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\\n구축 기관 (주)솔트룩스파트너스, (주)에버트란, (주)플리토\\n수집 정제 번역 검수 배포3\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼수집된 뉴스데이터 종류는 무엇인가요?Q\\nA대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스,'),\n",
       " Document(page_content='Q&A로 풀어본 \\nAI 학습용 데이터\\n상세 매뉴얼2019Q&A로 풀어본 \\nAI 학습용 데이터\\n상세 매뉴얼2019\\nContents\\n한국어-영어 번역 말뭉치 AI 데이터  2 1\\n이상행동 CCTV 영상 AI 데이터  6 2\\n한국어 글자체 이미지 AI 데이터  10 3\\n인도 보행 영상 AI 데이터  14 4\\n멀티모달 영상 AI 데이터  22 5\\n사람 동작 영상 AI데이터  26 6\\n한국인 안면 이미지 AI 데이터  30 7\\n위해물품 엑스레이 이미지 AI 데이터  34 8\\n질병진단 이미지 AI 데이터  38 9\\n이상행동 CCTV 영상 AI 데이터  45 102\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼한국어-영어 번역 말뭉치 AI 데이터\\n  세계는 이미 신경망 번역( NMT, Neural  Machine  Translation ) 엔진을 사용하는 것이 일반화되어, 용도에 맞는 제품과 \\n서비스를 만들어 기존의 번역을 혁신하는 단계가 되었으나, 국내 자동번역/인공지능 번역 연구개발은 대규모 고품질의 \\n말뭉치가 부족하여 개별 기업이 자체적 기술 개발에 한계\\n  최근 기업에 신경망 번역 엔진을 공식적으로 도입하여 사용하는 사례가 증가하고 향후 업무 활용 및 연구개발이 더욱 \\n활발해질 것으로 기대함에 따라 공공 번역 말뭉치를 구축하여 공개함 \\n  신경망 번역 성능 향상을 위한 고품질 한국어-영어 번역 말뭉치 셋 160만 문장 구축; 뉴스 80만, 지자체 웹사이트 10만, \\n조례 10만, 한국문화 10만, 구어체 40만, 대화체 10만1\\n구축 공정필요성  \\n구축 내용Q&A로 풀어본 AI 학습용 데이터 상세 매뉴얼\\n구축 기관 (주)솔트룩스파트너스, (주)에버트란, (주)플리토\\n수집 정제 번역 검수 배포3\\nQ&A로 풀어본 AI 학습용 데이터 상세 매뉴얼수집된 뉴스데이터 종류는 무엇인가요?Q\\nA대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스,')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \n",
      "한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 \n",
      "수집하였습니다.\n",
      "수집된 뉴스데이터 세부종류는 무엇인가요?Q\n",
      "A세부분류 항목은 문화, 경제, 정치, 스포츠, IT, 국제, 지역, 사회의 \n",
      "\n",
      "A대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, \n",
      "한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 \n",
      "수집하였습니다.\n",
      "수집된 뉴스데이터 세부종류는 무엇인가요?Q\n",
      "A세부분류 항목은 문화, 경제, 정치, 스포츠, IT, 국제, 지역, 사회의 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 수집하였습니다.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"수집된 뉴스데이터의 종류는?\"\n",
    "llm_response = qa_chain(query)\n",
    "llm_response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 대상매체는 국민일보, 내일신문, 노컷뉴스, 미디어오늘, 서울경제, 스포츠서울, 전자신문, 파이낸셜뉴스, 한겨레, SBS의 10개 매체이며, 발행일이 2018년 6월 1일부터 2019년 5월 31일 사이의 뉴스데이터를 수집하였습니다. 따라서 뉴스데이터가 수집된 종류는 총 10개이며, 문화, 경제, 정치, 스포츠, IT, 국제, 지역, 사회의 8개 항목으로 구분됩니다.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 본 데이터는 다양한 산업 분야에서 활용이 가능합니다. 예를 들어 스마트 교육, 스마트 관광, 스마트 공장/스토어 등에서 활용할 수 있습니다. 또한 OCR 기술을 활용한 자율주행, 증강현실, IoT 등의 산업분야에서도 활용이 가능합니다. 이미지를 인식하고 분류하는 기술을 개발하는데 사용할 수 있으며, 한글 글자체에 대한 학습용 데이터셋이 필요한 경우에도 사용할 수 있습니다. 따라서 데이터를 활용하는 방법은 다양하며, 적극적으로 활용하여 새로운 기술 및 서비스를 개발할 수 있습니다.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"데이터를 활용할 수 있는 방법은?\"\n",
    "llm_response = qa_chain(query)\n",
    "llm_response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 데이터 수집은 직접 촬영을 통해 조달하고 나머지는 협회와 계약 또는 공공저작물로 사용권이 허락된 데이터를 수집하는 방식을 사용했습니다. 또한 웹크롤링을 통해 데이터를 수집하기도 합니다.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"사물 이미지 데이터의 구축공정에서 데이터를 수집하는 방법은 무엇인가요?\"\n",
    "llm_response = qa_chain(query)\n",
    "llm_response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
