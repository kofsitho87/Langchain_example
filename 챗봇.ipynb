{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Chat specific components\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "I want you to act like a javascript/typescript interpreter. \n",
    "I will write you the code and you will respond with the output of the javascript/typescript interpreter. \n",
    "I want you to only reply with the terminal output inside one unique code block, and nothing else. \n",
    "do not write explanations. Do not type commands unless I instruct you to do so.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I want you to act like a javascript/typescript interpreter. \n",
      "I will write you the code and you will respond with the output of the javascript/typescript interpreter. \n",
      "I want you to only reply with the terminal output inside one unique code block, and nothing else. \n",
      "do not write explanations. Do not type commands unless I instruct you to do so.\n",
      "\n",
      "\n",
      "Human: How do I write asynchronous logic in JavaScript?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"```\\nüï∞Ô∏è Task: Write an asynchronous function that fetches data from an API and returns a promise.\\n\\nFunction: async function fetchData() {\\n  const response = await fetch('https://example.com/data');\\n  return response.json();\\n}\\n\\nOutput:\\n```\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm_chain.predict(\n",
    "  human_input=\"How do I write asynchronous logic in JavaScript?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I want you to act like a javascript/typescript interpreter. \n",
      "I will write you the code and you will respond with the output of the javascript/typescript interpreter. \n",
      "I want you to only reply with the terminal output inside one unique code block, and nothing else. \n",
      "do not write explanations. Do not type commands unless I instruct you to do so.\n",
      "\n",
      "Human: How do I write asynchronous logic in JavaScript?\n",
      "AI: ```\n",
      "üï∞Ô∏è Task: Write an asynchronous function that fetches data from an API and returns a promise.\n",
      "\n",
      "Function: async function fetchData() {\n",
      "  const response = await fetch('https://example.com/data');\n",
      "  return response.json();\n",
      "}\n",
      "\n",
      "Output:\n",
      "```\n",
      "Human: Using the asynchronous code you showed me before, let me know the code that sends the request post-wise to 'https://naver.com' and the body sends the request to query = 'computer' in json type\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"```\\nüìã Task: Write an asynchronous function that sends a POST request to 'https://naver.com' with a JSON body containing the query parameter 'computer'.\\n\\nFunction: async function sendRequest() {\\n  const response = await fetch('https://naver.com', {\\n    method: 'POST',\\n    headers: {\\n      'Content-Type': 'application/json'\\n    },\\n    body: JSON.stringify({ query: 'computer' })\\n  });\\n  return response.json();\\n}\\n\\nOutput:\\n```\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(\n",
    "  human_input=\"Using the asynchronous code you showed me before, let me know the code that sends the request post-wise to 'https://naver.com' and the body sends the request to query = 'computer' in json type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result\n",
    "\n",
    "```javascript\n",
    "  async function sendRequest() {\n",
    "    const response = await fetch('https://naver.com', {\n",
    "        method: 'POST',\n",
    "        headers: {\n",
    "          'Content-Type': 'application/json'\n",
    "        },\n",
    "        body: JSON.stringify({ query: 'computer' })\n",
    "    });\n",
    "    return response.json();\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I want you to act like a javascript/typescript interpreter. \n",
      "I will write you the code and you will respond with the output of the javascript/typescript interpreter. \n",
      "I want you to only reply with the terminal output inside one unique code block, and nothing else. \n",
      "do not write explanations. Do not type commands unless I instruct you to do so.\n",
      "\n",
      "Human: How do I write asynchronous logic in JavaScript?\n",
      "AI: ```\n",
      "üï∞Ô∏è Task: Write an asynchronous function that fetches data from an API and returns a promise.\n",
      "\n",
      "Function: async function fetchData() {\n",
      "  const response = await fetch('https://example.com/data');\n",
      "  return response.json();\n",
      "}\n",
      "\n",
      "Output:\n",
      "```\n",
      "Human: Using the asynchronous code you showed me before, let me know the code that sends the request post-wise to 'https://naver.com' and the body sends the request to query = 'computer' in json type\n",
      "AI: ```\n",
      "üìã Task: Write an asynchronous function that sends a POST request to 'https://naver.com' with a JSON body containing the query parameter 'computer'.\n",
      "\n",
      "Function: async function sendRequest() {\n",
      "  const response = await fetch('https://naver.com', {\n",
      "    method: 'POST',\n",
      "    headers: {\n",
      "      'Content-Type': 'application/json'\n",
      "    },\n",
      "    body: JSON.stringify({ query: 'computer' })\n",
      "  });\n",
      "  return response.json();\n",
      "}\n",
      "\n",
      "Output:\n",
      "```\n",
      "Human: Please change the sendRequest function to typecirpt and modify the code to execute sendRequest ('computer') by taking the query part of the body as a factor of the function\n",
      "AI: ```\n",
      "üï∞Ô∏è Task: Modify the `sendRequest` function to accept the query parameter as a function argument, rather than being hardcoded in the function body.\n",
      "\n",
      "Function: async function sendRequest(query) {\n",
      "  const response = await fetch('https://naver.com', {\n",
      "    method: 'POST',\n",
      "    headers: {\n",
      "      'Content-Type': 'application/json'\n",
      "    },\n",
      "    body: JSON.stringify({ query })\n",
      "  });\n",
      "  return response.json();\n",
      "}\n",
      "\n",
      "Output:\n",
      "```\n",
      "Human: Please change the sendRequest function to typscript grammer and modify the code to execute sendRequest ('computer') by taking the query part of the body as a factor of the function\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"üï∞Ô∏è Task: Modify the `sendRequest` function to accept the query parameter as a function argument, rather than being hardcoded in the function body.\\n\\nFunction: async function sendRequest(query: string) {\\n  const response = await fetch('https://naver.com', {\\n    method: 'POST',\\n    headers: {\\n      'Content-Type': 'application/json'\\n    },\\n    body: JSON.stringify({ query })\\n  });\\n  return response.json();\\n}\\n\\nOutput:\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(\n",
    "  human_input=\"Please change the sendRequest function to typscript grammer and modify the code to execute sendRequest ('computer') by taking the query part of the body as a factor of the function\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result\n",
    "\n",
    "``` javascript\n",
    "async function sendRequest(query: string) {\n",
    "  const response = await fetch('https://naver.com', {\n",
    "    method: 'POST',  \n",
    "    headers: {    \n",
    "    'Content-Type': 'application/json'  \n",
    "    },  \n",
    "    body: JSON.stringify({ query })\n",
    "  });\n",
    "  return response.json()\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
